{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lalwa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "import joblib\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "df = pd.read_csv(\"OnlineNewsPopularity.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "\n",
    "sharesclusters = df.shares.reshape(-1,1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(sharesclusters)\n",
    "labels = kmeans.labels_\n",
    "df['clusters'] = labels\n",
    "\n",
    "df = df.drop('shares',axis=1)\n",
    "df['popularity']= df['clusters']\n",
    "\n",
    "features_top15= ['LDA_00','LDA_02','is_weekend','weekday_is_friday','weekday_is_monday','weekday_is_thursday',\n",
    "                 'weekday_is_tuesday','weekday_is_wednesday','LDA_04', 'LDA_01','LDA_03','n_non_stop_unique_tokens',\n",
    "                'n_unique_tokens','avg_positive_polarity','avg_negative_polarity']\n",
    "\n",
    "X = df[features_top15]\n",
    "\n",
    "y = df['popularity']\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessing.MinMaxScaler(), \n",
    "                         RandomForestClassifier())\n",
    "hyperparameters = {'randomforestclassifier__n_estimators': [10,20,50,100,250,500],\n",
    "                    'randomforestclassifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "                  'randomforestclassifier__max_depth': [None, 5, 3, 1]}\n",
    "clf = GridSearchCV(pipeline,param_grid= hyperparameters,cv=5)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "clf.best_estimator_\n",
    "\n",
    "clf.predict(X_test)\n",
    "\n",
    "rfscore = clf.score(X_test,y_test)\n",
    "\n",
    "pkl_filename6 = \"RandomForest.pkl\"\n",
    "with open(pkl_filename6, 'wb') as file:  \n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrpipeline = make_pipeline(preprocessing.MinMaxScaler(), \n",
    "                         LogisticRegression('lbfgs'))\n",
    "parameters_LR = {\"logisticregression__penalty\": ['l1','l2'],\n",
    "              \"logisticregression__C\": [0.1,0.5,1.,2.,2.5,5]}\n",
    "lr = GridSearchCV(lrpipeline,param_grid= parameters_LR,cv=5)\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "lr.best_estimator_\n",
    "\n",
    "lrscore = lr.score(X_test,y_test)\n",
    "\n",
    "pkl_filenamel = \"LogisticRegression.pkl\"\n",
    "with open(pkl_filenamel, 'wb') as file:  \n",
    "    pickle.dump(lr, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapipeline = make_pipeline(preprocessing.MinMaxScaler(), \n",
    "                         AdaBoostClassifier())\n",
    "parameters_ADA = {\"adaboostclassifier__n_estimators\": [100,200,300,400],\n",
    "              \"adaboostclassifier__learning_rate\": [0.1,0.5,1]}\n",
    "ada = GridSearchCV(adapipeline,param_grid= parameters_ADA,cv=5)\n",
    "ada.fit(X_train,y_train)\n",
    "\n",
    "adascore = ada.score(X_test,y_test)\n",
    "\n",
    "ada.best_estimator_\n",
    "\n",
    "pkl_filename5 = \"AdaptiveBoosting.pkl\"\n",
    "with open(pkl_filename5, 'wb') as file:  \n",
    "    pickle.dump(ada, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralnets = make_pipeline(preprocessing.MinMaxScaler(), \n",
    "                         MLPClassifier())\n",
    "parameters_NN = {\"mlpclassifier__activation\": ['logistic','tanh','relu'],\n",
    "              \"mlpclassifier__learning_rate\": ['constant', 'invscaling', 'adaptive']}\n",
    "nn = GridSearchCV(neuralnets,param_grid= parameters_NN,cv=5)\n",
    "nn.fit(X_train,y_train)\n",
    "\n",
    "nn.best_estimator_\n",
    "\n",
    "nnscore = nn.score(X_test,y_test)\n",
    "\n",
    "pkl_filename8 = \"NeuralNetwork.pkl\"\n",
    "with open(pkl_filename8, 'wb') as file:  \n",
    "    pickle.dump(nn, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVCpipeline = make_pipeline(preprocessing.MinMaxScaler(), SVC())\n",
    "parameters_SVC = {}\n",
    "svc = GridSearchCV(SVCpipeline,param_grid= parameters_SVC,cv=5)\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "svcscore = svc.score(X_test,y_test)\n",
    "\n",
    "svc.best_estimator_\n",
    "\n",
    "pkl_filename3 = \"SupportVectorMachine.pkl\"\n",
    "with open(pkl_filename3, 'wb') as file:  \n",
    "    pickle.dump(svc, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbpipe = make_pipeline(preprocessing.MinMaxScaler(),GaussianNB())\n",
    "parameters_nb = {}\n",
    "nb = GridSearchCV(nbpipe,param_grid= parameters_nb,cv=5)\n",
    "nb.fit(X_train,y_train)\n",
    "\n",
    "nb.best_estimator_\n",
    "\n",
    "nbscore = nb.score(X_test,y_test)\n",
    "\n",
    "pkl_filename2 = \"NaiveBayes.pkl\"\n",
    "with open(pkl_filename2, 'wb') as file:  \n",
    "    pickle.dump(nb, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnpipe = make_pipeline(preprocessing.MinMaxScaler(),KNeighborsClassifier())\n",
    "parameters_knn = {}\n",
    "knn = GridSearchCV(knnpipe,param_grid= parameters_knn,cv=5)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "knn.best_estimator_\n",
    "\n",
    "knnscore = knn.score(X_test,y_test)\n",
    "\n",
    "pkl_filename7 = \"k-NearestNeighbors.pkl\"\n",
    "with open(pkl_filename7, 'wb') as file:  \n",
    "     pickle.dump(knn, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcpipe = make_pipeline(preprocessing.MinMaxScaler(),KNeighborsClassifier())\n",
    "parameters_dtc = {}\n",
    "dtc = GridSearchCV(dtcpipe,param_grid= parameters_dtc,cv=5)\n",
    "dtc.fit(X_train,y_train)\n",
    "\n",
    "dtc.best_estimator_\n",
    "\n",
    "dtcscore = dtc.score(X_test,y_test)\n",
    "\n",
    "pkl_filename4 = \"DecisionTree.pkl\"\n",
    "with open(pkl_filename4, 'wb') as file:  \n",
    "    pickle.dump(dtc, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Metrics to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Acc_GridSearch_Test = np.array([svcscore,rfscore,nnscore,knnscore,lrscore,dtcscore,adascore,nbscore])\n",
    "\n",
    "df2 = pd.read_csv('accuracyonlinenewprediction.csv',index_col ='rank')\n",
    "\n",
    "df2[\"Grid_Search\"] = Acc_GridSearch_Test\n",
    "\n",
    "newcols = ['Model','Accuracy_test','Accuracy_train', 'Grid_Search','F1_score_test','F1_score_train','Precision_test',\n",
    " 'Precision_train','Recall_test','Recall_train','Accuract with cv','Deviation(+/-)','time']\n",
    "\n",
    "df2 = df2[newcols]\n",
    "\n",
    "df2['Model'] = df2['Model'].replace({'NaiveBayers': 'NaiveBayes'}) \n",
    "\n",
    "df2.to_csv(\"Evaluation_Metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So here after grid search cross validation on kmeans clusters we see Random Forest , SVC, Neural Networks, KNN work almost the same i.e. giving almost same accuracy. So we conclude all these models as good models and select any one of these models for further predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
